{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.4.2 (from gradio)\n",
      "  Using cached gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.11-cp310-none-win_amd64.whl.metadata (52 kB)\n",
      "     ---------------------------------------- 0.0/52.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 52.0/52.0 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.2.1)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart==0.0.12 (from gradio)\n",
      "  Using cached python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.7.3-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
      "  Using cached safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio-client==1.4.2->gradio) (2024.3.1)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
      "  Downloading websockets-12.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.23.4-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
      "   ---------------------------------------- 0.0/56.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/56.7 MB 5.2 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.6/56.7 MB 6.1 MB/s eta 0:00:10\n",
      "    --------------------------------------- 1.0/56.7 MB 6.8 MB/s eta 0:00:09\n",
      "    --------------------------------------- 1.4/56.7 MB 7.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.9/56.7 MB 8.0 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 2.5/56.7 MB 8.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 3.2/56.7 MB 9.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 3.9/56.7 MB 10.3 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 4.6/56.7 MB 10.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 5.3/56.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 6.1/56.7 MB 11.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 6.8/56.7 MB 12.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 7.5/56.7 MB 12.3 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 8.2/56.7 MB 12.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 8.9/56.7 MB 12.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 9.7/56.7 MB 12.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 10.4/56.7 MB 13.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 11.2/56.7 MB 14.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 11.9/56.7 MB 15.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 12.6/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 13.4/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 14.1/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 14.9/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 15.5/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 16.2/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 16.9/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 17.6/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 18.0/56.7 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 18.1/56.7 MB 13.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 18.2/56.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 18.4/56.7 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 18.9/56.7 MB 12.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 19.6/56.7 MB 12.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 20.4/56.7 MB 12.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 21.1/56.7 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 21.8/56.7 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 22.6/56.7 MB 12.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 23.2/56.7 MB 12.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 23.9/56.7 MB 12.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 24.7/56.7 MB 12.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 25.4/56.7 MB 12.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 26.2/56.7 MB 12.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 26.9/56.7 MB 12.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 27.7/56.7 MB 12.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 28.5/56.7 MB 14.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 29.3/56.7 MB 16.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 30.1/56.7 MB 16.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 30.9/56.7 MB 16.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 31.7/56.7 MB 16.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 32.6/56.7 MB 16.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 33.4/56.7 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 34.3/56.7 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 35.2/56.7 MB 17.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 36.1/56.7 MB 17.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 37.0/56.7 MB 17.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 37.9/56.7 MB 18.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 38.8/56.7 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 39.7/56.7 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 40.6/56.7 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 41.5/56.7 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 42.4/56.7 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 43.4/56.7 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 44.3/56.7 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 45.3/56.7 MB 19.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 46.3/56.7 MB 19.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 47.3/56.7 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 48.2/56.7 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 49.3/56.7 MB 20.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 50.2/56.7 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 51.3/56.7 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 52.2/56.7 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 53.2/56.7 MB 21.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 54.3/56.7 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  55.3/56.7 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.4/56.7 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.7/56.7 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.7/56.7 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.7/56.7 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.7/56.7 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.7/56.7 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.7/56.7 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.7/56.7 MB 13.6 MB/s eta 0:00:00\n",
      "Using cached gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
      "Using cached python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
      "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "   ---------------------------------------- 0.0/94.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 94.9/94.9 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.0/78.0 kB ? eta 0:00:00\n",
      "Downloading orjson-3.10.11-cp310-none-win_amd64.whl (136 kB)\n",
      "   ---------------------------------------- 0.0/136.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 136.4/136.4 kB 7.9 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.2/1.9 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 20.3 MB/s eta 0:00:00\n",
      "Downloading ruff-0.7.3-py3-none-win_amd64.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.4 MB 26.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.9/9.4 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.1/9.4 MB 24.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.4 MB 22.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.0/9.4 MB 23.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.1/9.4 MB 23.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.3/9.4 MB 23.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.4/9.4 MB 23.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.4 MB 23.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.4 MB 23.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.4/9.4 MB 20.1 MB/s eta 0:00:00\n",
      "Using cached safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "Downloading typer-0.13.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.2/44.2 kB ? eta 0:00:00\n",
      "Using cached uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Using cached ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading websockets-12.0-cp310-cp310-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB ? eta 0:00:00\n",
      "Installing collected packages: pydub, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, pydantic-core, orjson, h11, ffmpy, annotated-types, aiofiles, uvicorn, starlette, pydantic, httpcore, typer, httpx, fastapi, safehttpx, gradio-client, gradio\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 orjson-3.10.11 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.41.2 tomlkit-0.12.0 typer-0.13.0 uvicorn-0.32.0 websockets-12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import gradio as gr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath='SMSSpamCollection.csv'):\n",
    "    \"\"\"\n",
    "    Load and prepare the SMS spam dataset with validation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset with proper delimiter\n",
    "        df = pd.read_csv(filepath, delimiter='\\t', names=['label', 'message'])\n",
    "        \n",
    "        # Drop any rows with NaN values\n",
    "        df = df.dropna(subset=['label', 'message']).reset_index(drop=True)\n",
    "        \n",
    "        # Convert labels to binary format\n",
    "        df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "        \n",
    "        # Check class distribution\n",
    "        class_dist = df['label'].value_counts()\n",
    "        print(\"Class distribution:\\n\", class_dist)\n",
    "        print(\"\\nSample data:\\n\", df.head())\n",
    "        \n",
    "        # Validate that we have at least two classes\n",
    "        if len(class_dist) < 2:\n",
    "            print(\"\\nWARNING: Dataset contains only one class:\", \n",
    "                  \"ham\" if class_dist.index[0] == 0 else \"spam\")\n",
    "            print(\"Please ensure your dataset contains both spam and ham messages.\")\n",
    "            return None\n",
    "            \n",
    "        # Validate minimum samples per class\n",
    "        min_samples = min(class_dist)\n",
    "        if min_samples < 2:\n",
    "            print(f\"\\nWARNING: Insufficient samples in one or more classes. Minimum required: 2, Found: {min_samples}\")\n",
    "            return None\n",
    "            \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, use_kfold=False):\n",
    "    \"\"\"\n",
    "    Train the SMS classification model with validation checks\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        raise ValueError(\"No valid dataset provided. Please check the data loading errors above.\")\n",
    "        \n",
    "    if len(df) < 2:\n",
    "        raise ValueError(\"Dataset too small to train a model.\")\n",
    "        \n",
    "    features = df['message']\n",
    "    target = df['label']\n",
    "    \n",
    "    # Verify we have at least two classes\n",
    "    unique_classes = np.unique(target)\n",
    "    if len(unique_classes) < 2:\n",
    "        raise ValueError(f\"Cannot train binary classifier with only one class: {unique_classes[0]}\")\n",
    "    \n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "        ('classifier', LinearSVC(dual=False, max_iter=1000))\n",
    "    ])\n",
    "\n",
    "    # Determine if we have enough samples for k-fold\n",
    "    min_samples_per_class = min(np.bincount(target))\n",
    "    if use_kfold and min_samples_per_class >= 5:\n",
    "        n_splits = min(5, min_samples_per_class)\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        fold_accuracies = []\n",
    "        for fold, (train_idx, test_idx) in enumerate(skf.split(features, target), 1):\n",
    "            X_train, X_test = features.iloc[train_idx], features.iloc[test_idx]\n",
    "            y_train, y_test = target.iloc[train_idx], target.iloc[test_idx]\n",
    "            \n",
    "            pipeline.fit(X_train, y_train)\n",
    "            accuracy = pipeline.score(X_test, y_test)\n",
    "            fold_accuracies.append(accuracy)\n",
    "            print(f\"Fold {fold} accuracy: {accuracy:.3f}\")\n",
    "        \n",
    "        print(f\"\\nAverage accuracy: {np.mean(fold_accuracies):.3f}\")\n",
    "    else:\n",
    "        # Use simple train-test split\n",
    "        test_size = min(0.2, 1.0 / min_samples_per_class)  # Adjust test size for small datasets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            features, target, test_size=test_size, random_state=42, stratify=target\n",
    "        )\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        accuracy = pipeline.score(X_test, y_test)\n",
    "        print(f\"\\nTest accuracy: {accuracy:.3f}\")\n",
    "    \n",
    "    # Fit final model on all data\n",
    "    pipeline.fit(features, target)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spam(text, model):\n",
    "    \"\"\"\n",
    "    Make prediction on new text with error handling\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return \"Error: Please provide valid text input\"\n",
    "    if not model:\n",
    "        return \"Error: Model not properly trained\"\n",
    "    \n",
    "    try:\n",
    "        prediction = model.predict([text])[0]\n",
    "        confidence = \"high\"  # Note: LinearSVC doesn't provide probability scores\n",
    "        result = \"spam\" if prediction == 1 else \"ham\"\n",
    "        return f\"Prediction: {result} (confidence: {confidence})\"\n",
    "    except Exception as e:\n",
    "        return f\"Error making prediction: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradio_interface(model):\n",
    "    \"\"\"\n",
    "    Create and launch Gradio interface for the spam classifier\n",
    "    \"\"\"\n",
    "    def classify_text(message):\n",
    "        return predict_spam(message, model)\n",
    "\n",
    "    interface = gr.Interface(\n",
    "        fn=classify_text,\n",
    "        inputs=gr.Textbox(\n",
    "            lines=2,\n",
    "            placeholder=\"Enter SMS text here...\",\n",
    "            label=\"Message Text\"\n",
    "        ),\n",
    "        outputs=gr.Textbox(label=\"Classification Result\"),\n",
    "        title=\"SMS Spam Detector\",\n",
    "        description=\"Classify SMS messages as spam or ham (non-spam).\",\n",
    "        examples=[\n",
    "            [\"Congratulations! You've won a $1000 prize! Click here to claim now!\"],\n",
    "            [\"Hey, can we meet at 6pm for dinner tonight?\"]\n",
    "        ]\n",
    "    )\n",
    "    return interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      " label\n",
      "0    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data:\n",
      "    label                                            message\n",
      "0      0        Yeah, give me a call if you've got a minute\n",
      "1      0  HI BABE UAWAKE?FEELLIKW SHIT.JUSTFOUND OUT VIA...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_kfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Create and launch the Gradio interface\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     interface \u001b[38;5;241m=\u001b[39m create_gradio_interface(model)\n",
      "Cell \u001b[1;32mIn[28], line 37\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(df, use_kfold)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Use simple train-test split for small datasets\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     35\u001b[0m         features, target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtarget\n\u001b[0;32m     36\u001b[0m     )\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    474\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\svm\\_classes.py:325\u001b[0m, in \u001b[0;36mLinearSVC.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m    321\u001b[0m _dual \u001b[38;5;241m=\u001b[39m _validate_dual_parameter(\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, X\n\u001b[0;32m    323\u001b[0m )\n\u001b[1;32m--> 325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_dual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# Backward compatibility: _fit_liblinear is used both by LinearSVC/R\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# and LogisticRegression but LogisticRegression sets a structured\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# `n_iter_` attribute with information about the underlying OvR fits\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# while LinearSVC/R only reports the maximum value.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m n_iter_\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\spenc\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\svm\\_base.py:1174\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     classes_ \u001b[38;5;241m=\u001b[39m enc\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(classes_) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1174\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1175\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1178\u001b[0m             \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1179\u001b[0m         )\n\u001b[0;32m   1181\u001b[0m     class_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(class_weight, classes\u001b[38;5;241m=\u001b[39mclasses_, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    df = load_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Train the model\n",
    "        model = train_model(df, use_kfold=True)\n",
    "        \n",
    "        # Create and launch the Gradio interface\n",
    "        interface = create_gradio_interface(model)\n",
    "        interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SMS spam detection system...\n",
      "Please ensure your dataset contains both spam and ham messages.\n",
      "Class distribution:\n",
      " label\n",
      "0    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data:\n",
      "    label                                            message\n",
      "0      0        Yeah, give me a call if you've got a minute\n",
      "1      0  HI BABE UAWAKE?FEELLIKW SHIT.JUSTFOUND OUT VIA...\n",
      "\n",
      "WARNING: Dataset contains only one class: ham\n",
      "Please ensure your dataset contains both spam and ham messages.\n",
      "\n",
      "Failed to initialize the system due to data loading errors.\n",
      "Please ensure your dataset is properly formatted and contains both spam and ham messages.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading SMS spam detection system...\")\n",
    "    print(\"Please ensure your dataset contains both spam and ham messages.\")\n",
    "    \n",
    "    # Load and prepare data\n",
    "    df = load_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        try:\n",
    "            # Train the model\n",
    "            model = train_model(df, use_kfold=True)\n",
    "            \n",
    "            # Create and launch the Gradio interface\n",
    "            interface = create_gradio_interface(model)\n",
    "            interface.launch()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n",
    "            print(\"Please check your dataset and try again.\")\n",
    "    else:\n",
    "        print(\"\\nFailed to initialize the system due to data loading errors.\")\n",
    "        print(\"Please ensure your dataset is properly formatted and contains both spam and ham messages.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
